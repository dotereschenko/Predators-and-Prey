{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1\n",
    "\n",
    "This is the notebook for doing stage1 competition for training Predators and Prey agent which will hunt preys.\n",
    "\n",
    "Implemented solution:\n",
    " \n",
    " * Process the state in such way that there will be  3 channels where first channel is the location of preys, second is the barriers and third is a centered location of the predator.\n",
    " * Limit the view for predators. The state was cut to 20x20 size.\n",
    " * For this stage the independent agent learning was applied, which means that during DQN only one predators was participating in hunting. The Logic was motivated by the fact if one can hunt the model can be applied to other predators.\n",
    " * The reward function is based on idea that its good to reward for making the right movement as well as giving reward for eating a prey. The more it eats the higher is coefficient for reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "from world.realm import Realm\n",
    "from world.map_loaders.base import MixedMapLoader\n",
    "from world.map_loaders.single_team import SingleTeamLabyrinthMapLoader, SingleTeamRocksMapLoader\n",
    "from world.utils import RenderedEnvWrapper\n",
    "from world.envs import OnePlayerEnv\n",
    "from world.scripted_agents import ClosestTargetAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from itertools import count\n",
    "from sys import getsizeof\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from collections import deque, namedtuple\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env =  RenderedEnvWrapper(OnePlayerEnv(Realm(MixedMapLoader(\n",
    "    (SingleTeamLabyrinthMapLoader(), SingleTeamRocksMapLoader())\n",
    "    ), 1, playable_team_size=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scripted agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ClosestTargetAgent()\n",
    "state, info = env.reset()\n",
    "agent.reset(state,0)\n",
    "done = False\n",
    "count = 0\n",
    "while  not done:\n",
    "    action = agent.get_actions(state,0)\n",
    "    next_state,done,info = env.step(action)\n",
    "    state = next_state\n",
    "env.render()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./render/301.gif\" width=\"250\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu, seed: 3141\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 3141\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "print(f'Device: {device}, seed: {SEED}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essentials for working with state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll(arr, x, y):\n",
    "    \"\"\"\n",
    "    arr is [barrier_mask, preys_mask, predators_mask]\n",
    "    \"\"\"\n",
    "    height, width = arr.shape[1], arr.shape[2]\n",
    "    dx = width // 2 - x\n",
    "    dy = height // 2 - y\n",
    "    res = np.roll(a=arr, shift=(dx, dy), axis=(2, 1))\n",
    "    return res\n",
    "\n",
    "\n",
    "def prepare_state(state):\n",
    "    \"\"\"\n",
    "    Take state and return three masks: barrier positions, \n",
    "    preys positions and predator positions\n",
    "    \"\"\"\n",
    "    barrier_mask = np.logical_and(state[:, :, 0] == -1, state[:, :, 1] == -1)\n",
    "    preys_mask = state[:, :, 0] > 0\n",
    "    predators_mask = np.logical_and(state[:, :, 0] == 0, state[:, :, 1] >= 0)\n",
    "    return barrier_mask, preys_mask, predators_mask\n",
    "\n",
    "def single_agent_state(state, info):\n",
    "    res = prepare_state(state)\n",
    "    res = np.stack(res)\n",
    "    x, y = info['predators'][0]['x'], info['predators'][0]['y']\n",
    "    centered = roll(res, x, y)\n",
    "    return centered[:, 10:30, 10:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "                        \n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim=(20, 20, 3), output_dim=5):\n",
    "        super().__init__()\n",
    "#         self.output_dim = output_dim\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=128, kernel_size=7, stride=5, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5, stride=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=5, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_dim)            \n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x: torch.FloatTensor):\n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([np.random.randint(0, high=5, size=1, dtype=int)], device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(\n",
    "        info,\n",
    "        step_reward=0.1,\n",
    "        step_coef=0.99, \n",
    "        kill_reward=1.,\n",
    "        kill_coef=1.01\n",
    "        ):\n",
    "    step = step_coef ** info['step'] * (np.array(info['true_action']) * step_reward)\n",
    "    kill = kill_coef ** info['all_eated'] * (kill_reward * np.array(info['eated_on_step']))\n",
    "    return step + kill\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters and essential initialisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.99\n",
    "EPS_START = 1.0\n",
    "EPS_END = 0.02\n",
    "EPS_DECAY = 100000\n",
    "TAU = 0.01\n",
    "LR = 5 * 1e-4\n",
    "TRANSITIONS = 1000\n",
    "EVAL_STEP = 5\n",
    "UPDATE_STEP = 500\n",
    "NUM_EPISODES = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_net = DQN().to(device)\n",
    "target_net = DQN().to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "memory = ReplayMemory(50000)\n",
    "steps_done = 0\n",
    "n_actions = 5\n",
    "best_score = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_two_map(model, episod):\n",
    "    env = RenderedEnvWrapper(OnePlayerEnv(Realm(SingleTeamLabyrinthMapLoader(), 1, playable_team_size=1)))\n",
    "    state, info = env.reset()\n",
    "    state = torch.tensor(single_agent_state(state, info), dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    done = False\n",
    "    step = 0\n",
    "    model.eval()\n",
    "    while not done:\n",
    "        action = model(state).max(1)[1].view(1, 1)\n",
    "        state, done, info = env.step(action.squeeze(0).cpu().numpy())\n",
    "        state = torch.tensor(single_agent_state(state, info), dtype=torch.float32, device=device).unsqueeze(0)\n",
    "        step += 1\n",
    "    env.render()\n",
    "    score_1 = int(info['all_eated'][0])\n",
    "    \n",
    "    env = RenderedEnvWrapper(OnePlayerEnv(Realm(SingleTeamRocksMapLoader(), 1, playable_team_size=1)))\n",
    "    state, info = env.reset()\n",
    "    state = torch.tensor(single_agent_state(state, info), dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    done = False\n",
    "    step = 0\n",
    "    while not done:\n",
    "        action = model(state).max(1)[1].view(1, 1)\n",
    "        state, done, info = env.step(action.squeeze(0).cpu().numpy())\n",
    "        state = torch.tensor(single_agent_state(state, info), dtype=torch.float32, device=device).unsqueeze(0)\n",
    "        step += 1\n",
    "    env.render()\n",
    "    score_2 = int(info['all_eated'][0])\n",
    "    score_union = (score_1 + score_2) // 2\n",
    "    return {\n",
    "        'mean_score': score_union,\n",
    "        'score_1': score_1,\n",
    "        'score_2': score_2\n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_numbers = []\n",
    "best_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868658e9abc046308dc526ef5e79d6b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nh/5_1n3ycs0f3g8ltxlc_pcr6m0000gn/T/ipykernel_2049/2408990318.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:276.)\n",
      "  return torch.tensor([np.random.randint(0, high=5, size=1, dtype=int)], device=device, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:2, 1st:1, 2nd:4\n",
      "Mean:8, 1st:9, 2nd:7\n",
      "Mean:9, 1st:5, 2nd:14\n",
      "Mean:11, 1st:8, 2nd:14\n",
      "Mean:12, 1st:10, 2nd:14\n",
      "Mean:14, 1st:12, 2nd:17\n",
      "Mean:7, 1st:4, 2nd:11\n",
      "Mean:13, 1st:6, 2nd:20\n",
      "Mean:18, 1st:18, 2nd:18\n",
      "Mean:16, 1st:11, 2nd:21\n",
      "Mean:2, 1st:2, 2nd:3\n",
      "Mean:15, 1st:14, 2nd:17\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/denisteresenko/Progamming/Predators and Prey/Predators-and-Prey/stage1.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/denisteresenko/Progamming/Predators%20and%20Prey/Predators-and-Prey/stage1.ipynb#X31sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m memory\u001b[39m.\u001b[39mpush(state, action, next_state, reward)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/denisteresenko/Progamming/Predators%20and%20Prey/Predators-and-Prey/stage1.ipynb#X31sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m state \u001b[39m=\u001b[39m next_state\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/denisteresenko/Progamming/Predators%20and%20Prey/Predators-and-Prey/stage1.ipynb#X31sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m loss \u001b[39m=\u001b[39m optimize_model()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/denisteresenko/Progamming/Predators%20and%20Prey/Predators-and-Prey/stage1.ipynb#X31sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mif\u001b[39;00m steps_done \u001b[39m%\u001b[39m UPDATE_STEP \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/denisteresenko/Progamming/Predators%20and%20Prey/Predators-and-Prey/stage1.ipynb#X31sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     target_net_state_dict \u001b[39m=\u001b[39m target_net\u001b[39m.\u001b[39mstate_dict()\n",
      "\u001b[1;32m/Users/denisteresenko/Progamming/Predators and Prey/Predators-and-Prey/stage1.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/denisteresenko/Progamming/Predators%20and%20Prey/Predators-and-Prey/stage1.ipynb#X31sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m next_state_values \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(BATCH_SIZE, device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/denisteresenko/Progamming/Predators%20and%20Prey/Predators-and-Prey/stage1.ipynb#X31sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/denisteresenko/Progamming/Predators%20and%20Prey/Predators-and-Prey/stage1.ipynb#X31sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     next_state_values[non_final_mask] \u001b[39m=\u001b[39m target_net(non_final_next_states)\u001b[39m.\u001b[39mmax(\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/denisteresenko/Progamming/Predators%20and%20Prey/Predators-and-Prey/stage1.ipynb#X31sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m expected_state_action_values \u001b[39m=\u001b[39m (next_state_values \u001b[39m*\u001b[39m GAMMA) \u001b[39m+\u001b[39m reward_batch\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/denisteresenko/Progamming/Predators%20and%20Prey/Predators-and-Prey/stage1.ipynb#X31sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSmoothL1Loss()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/ML_clone/lib/python3.9/site-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1518\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1519\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/ML_clone/lib/python3.9/site-packages/torch/nn/modules/module.py:1528\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1527\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1528\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1530\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1531\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/Users/denisteresenko/Progamming/Predators and Prey/Predators-and-Prey/stage1.ipynb Cell 23\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/denisteresenko/Progamming/Predators%20and%20Prey/Predators-and-Prey/stage1.ipynb#X31sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mFloatTensor):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/denisteresenko/Progamming/Predators%20and%20Prey/Predators-and-Prey/stage1.ipynb#X31sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq(x)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/ML_clone/lib/python3.9/site-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1518\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1519\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/ML_clone/lib/python3.9/site-packages/torch/nn/modules/module.py:1528\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1527\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1528\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1530\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1531\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/ML_clone/lib/python3.9/site-packages/torch/nn/modules/container.py:216\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    215\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 216\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    217\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/ML_clone/lib/python3.9/site-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1518\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1519\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/ML_clone/lib/python3.9/site-packages/torch/nn/modules/module.py:1528\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1527\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1528\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1530\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1531\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/ML_clone/lib/python3.9/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/ML_clone/lib/python3.9/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i_episode in tqdm(range(NUM_EPISODES)):\n",
    "    state, info = env.reset()\n",
    "    state = torch.tensor(single_agent_state(state, info), dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    for t in count():\n",
    "        action = select_action(state)\n",
    "        observation, done, info = env.step(action.squeeze(0).cpu().numpy())\n",
    "        reward = torch.tensor(get_reward(info), dtype=torch.float32, device=device)\n",
    "        next_state = torch.tensor(single_agent_state(observation, info), dtype=torch.float32, device=device).unsqueeze(0)\n",
    "        memory.push(state, action, next_state, reward)\n",
    "        state = next_state\n",
    "        loss = optimize_model()\n",
    "\n",
    "\n",
    "        if steps_done % UPDATE_STEP == 0:\n",
    "            target_net_state_dict = target_net.state_dict()\n",
    "            policy_net_state_dict = policy_net.state_dict()\n",
    "            for key in policy_net_state_dict:\n",
    "                target_net_state_dict[key] = policy_net_state_dict[key] * TAU + target_net_state_dict[key] * (1 - TAU)\n",
    "            target_net.load_state_dict(target_net_state_dict)\n",
    "            \n",
    "        if done:\n",
    "            break\n",
    "    if i_episode and i_episode % EVAL_STEP == 0:\n",
    "        eval_result = evaluation_two_map(policy_net, i_episode)\n",
    "        print(f\"Mean:{eval_result['mean_score']}, 1st:{eval_result['score_1']}, 2nd:{eval_result['score_2']}\")\n",
    "        if eval_result['mean_score'] > best_score:\n",
    "            best_score = eval_result['mean_score']\n",
    "            best_scores.append(best_score)\n",
    "            episode_numbers.append(i_episode)\n",
    "            plt.plot(episode_numbers, best_scores, marker='o', linestyle='-')\n",
    "            plt.xlabel('episode')\n",
    "            plt.ylabel('best score')\n",
    "            plt.grid(True)\n",
    "            \n",
    "            plt.savefig(f'agent_training.png')\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](agent_training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_tasks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
